2025-04-19 17:49:45,955 | Logging to: decoder_logs/decoder_train_20250419_174945.log
2025-04-19 17:49:56,413 | === Starting Training ===
2025-04-19 17:50:00,497 | Epoch [1/3] Batch [100] Loss: 9.8778
2025-04-19 17:50:02,951 | Epoch [1/3] Batch [200] Loss: 7.9394
2025-04-19 17:50:05,416 | Epoch [1/3] Batch [300] Loss: 7.2498
2025-04-19 17:50:07,885 | Epoch [1/3] Batch [400] Loss: 7.1220
2025-04-19 17:50:10,359 | Epoch [1/3] Batch [500] Loss: 7.0283
2025-04-19 17:50:12,834 | Epoch [1/3] Batch [600] Loss: 6.8930
2025-04-19 17:50:15,300 | Epoch [1/3] Batch [700] Loss: 6.8464
2025-04-19 17:50:17,758 | Epoch [1/3] Batch [800] Loss: 6.8564
2025-04-19 17:50:20,217 | Epoch [1/3] Batch [900] Loss: 6.8474
2025-04-19 17:50:22,678 | Epoch [1/3] Batch [1000] Loss: 6.7959
2025-04-19 17:50:25,138 | Epoch [1/3] Batch [1100] Loss: 6.7381
2025-04-19 17:50:27,598 | Epoch [1/3] Batch [1200] Loss: 6.7177
2025-04-19 17:50:30,062 | Epoch [1/3] Batch [1300] Loss: 6.5879
2025-04-19 17:50:32,513 | Epoch [1/3] Batch [1400] Loss: 6.6092
2025-04-19 17:50:34,960 | Epoch [1/3] Batch [1500] Loss: 6.5300
2025-04-19 17:50:37,399 | Epoch [1/3] Batch [1600] Loss: 6.4530
2025-04-19 17:50:39,835 | Epoch [1/3] Batch [1700] Loss: 6.5213
2025-04-19 17:50:42,270 | Epoch [1/3] Batch [1800] Loss: 6.4479
2025-04-19 17:50:44,707 | Epoch [1/3] Batch [1900] Loss: 6.4707
2025-04-19 17:50:47,144 | Epoch [1/3] Batch [2000] Loss: 6.3686
2025-04-19 17:50:49,581 | Epoch [1/3] Batch [2100] Loss: 6.3297
2025-04-19 17:50:52,018 | Epoch [1/3] Batch [2200] Loss: 6.2658
2025-04-19 17:50:54,458 | Epoch [1/3] Batch [2300] Loss: 6.3215
2025-04-19 17:50:56,896 | Epoch [1/3] Batch [2400] Loss: 6.2377
2025-04-19 17:50:59,333 | Epoch [1/3] Batch [2500] Loss: 6.1338
2025-04-19 17:51:01,771 | Epoch [1/3] Batch [2600] Loss: 6.1448
2025-04-19 17:51:04,229 | Epoch [1/3] Batch [2700] Loss: 6.0327
2025-04-19 17:51:06,670 | Epoch [1/3] Batch [2800] Loss: 6.1130
2025-04-19 17:51:09,107 | Epoch [1/3] Batch [2900] Loss: 6.0459
2025-04-19 17:51:11,546 | Epoch [1/3] Batch [3000] Loss: 6.1382
2025-04-19 17:51:13,988 | Epoch [1/3] Batch [3100] Loss: 6.0945
2025-04-19 17:51:16,430 | Epoch [1/3] Batch [3200] Loss: 6.0552
2025-04-19 17:51:18,873 | Epoch [1/3] Batch [3300] Loss: 5.9665
2025-04-19 17:51:21,314 | Epoch [1/3] Batch [3400] Loss: 5.9477
2025-04-19 17:51:23,756 | Epoch [1/3] Batch [3500] Loss: 5.9051
2025-04-19 17:51:26,198 | Epoch [1/3] Batch [3600] Loss: 5.8626
2025-04-19 17:51:28,640 | Epoch [1/3] Batch [3700] Loss: 5.9450
2025-04-19 17:51:31,083 | Epoch [1/3] Batch [3800] Loss: 5.8845
2025-04-19 17:51:33,534 | Epoch [1/3] Batch [3900] Loss: 5.8045
2025-04-19 17:51:35,990 | Epoch [1/3] Batch [4000] Loss: 5.8143
2025-04-19 17:51:38,432 | Epoch [1/3] Batch [4100] Loss: 5.8238
2025-04-19 17:51:40,874 | Epoch [1/3] Batch [4200] Loss: 5.8378
2025-04-19 17:51:43,317 | Epoch [1/3] Batch [4300] Loss: 5.8234
2025-04-19 17:51:45,759 | Epoch [1/3] Batch [4400] Loss: 5.8462
2025-04-19 17:51:48,202 | Epoch [1/3] Batch [4500] Loss: 5.7635
2025-04-19 17:51:50,647 | Epoch [1/3] Batch [4600] Loss: 5.7910
2025-04-19 17:51:53,091 | Epoch [1/3] Batch [4700] Loss: 5.7626
2025-04-19 17:51:55,533 | Epoch [1/3] Batch [4800] Loss: 5.7784
2025-04-19 17:51:57,979 | Epoch [1/3] Batch [4900] Loss: 5.6482
2025-04-19 17:52:00,420 | Epoch [1/3] Batch [5000] Loss: 5.6203
2025-04-19 17:52:02,867 | Epoch [1/3] Batch [5100] Loss: 5.6705
2025-04-19 17:52:05,332 | Epoch [1/3] Batch [5200] Loss: 5.6964
2025-04-19 17:52:07,775 | Epoch [1/3] Batch [5300] Loss: 5.6672
2025-04-19 17:52:10,218 | Epoch [1/3] Batch [5400] Loss: 5.6344
2025-04-19 17:52:12,661 | Epoch [1/3] Batch [5500] Loss: 5.5580
2025-04-19 17:52:15,105 | Epoch [1/3] Batch [5600] Loss: 5.4810
2025-04-19 17:52:17,546 | Epoch [1/3] Batch [5700] Loss: 5.4781
2025-04-19 17:52:19,992 | Epoch [1/3] Batch [5800] Loss: 5.5114
2025-04-19 17:52:22,436 | Epoch [1/3] Batch [5900] Loss: 5.5156
2025-04-19 17:52:24,880 | Epoch [1/3] Batch [6000] Loss: 5.4908
2025-04-19 17:52:27,323 | Epoch [1/3] Batch [6100] Loss: 5.5009
2025-04-19 17:52:29,763 | Epoch [1/3] Batch [6200] Loss: 5.5720
2025-04-19 17:52:32,211 | Epoch [1/3] Batch [6300] Loss: 5.4623
2025-04-19 17:52:34,678 | Epoch [1/3] Batch [6400] Loss: 5.4075
2025-04-19 17:52:37,144 | Epoch [1/3] Batch [6500] Loss: 5.4351
2025-04-19 17:52:39,611 | Epoch [1/3] Batch [6600] Loss: 5.3790
2025-04-19 17:52:42,078 | Epoch [1/3] Batch [6700] Loss: 5.4321
2025-04-19 17:52:44,544 | Epoch [1/3] Batch [6800] Loss: 5.3443
2025-04-19 17:52:47,009 | Epoch [1/3] Batch [6900] Loss: 5.4615
2025-04-19 17:52:49,481 | Epoch [1/3] Batch [7000] Loss: 5.3569
2025-04-19 17:52:51,969 | Epoch [1/3] Batch [7100] Loss: 5.3158
2025-04-19 17:52:54,457 | Epoch [1/3] Batch [7200] Loss: 5.3332
2025-04-19 17:52:56,943 | Epoch [1/3] Batch [7300] Loss: 5.2964
2025-04-19 17:52:59,431 | Epoch [1/3] Batch [7400] Loss: 5.3441
2025-04-19 17:53:01,899 | Epoch [1/3] Batch [7500] Loss: 5.3480
2025-04-19 17:53:04,380 | Epoch [1/3] Batch [7600] Loss: 5.1952
2025-04-19 17:53:06,848 | Epoch [1/3] Batch [7700] Loss: 5.2932
2025-04-19 17:53:09,316 | Epoch [1/3] Batch [7800] Loss: 5.2919
2025-04-19 17:53:11,784 | Epoch [1/3] Batch [7900] Loss: 5.1504
2025-04-19 17:53:14,252 | Epoch [1/3] Batch [8000] Loss: 5.2480
2025-04-19 17:53:16,707 | Epoch [1/3] Batch [8100] Loss: 5.1781
2025-04-19 17:53:19,150 | Epoch [1/3] Batch [8200] Loss: 5.3614
2025-04-19 17:53:21,592 | Epoch [1/3] Batch [8300] Loss: 5.1741
2025-04-19 17:53:24,036 | Epoch [1/3] Batch [8400] Loss: 5.1174
2025-04-19 17:53:26,481 | Epoch [1/3] Batch [8500] Loss: 5.1480
2025-04-19 17:53:28,924 | Epoch [1/3] Batch [8600] Loss: 5.1532
2025-04-19 17:53:31,369 | Epoch [1/3] Batch [8700] Loss: 5.0499
2025-04-19 17:53:33,815 | Epoch [1/3] Batch [8800] Loss: 5.0775
2025-04-19 17:53:36,262 | Epoch [1/3] Batch [8900] Loss: 5.0819
2025-04-19 17:53:38,709 | Epoch [1/3] Batch [9000] Loss: 5.0583
2025-04-19 17:53:41,154 | Epoch [1/3] Batch [9100] Loss: 5.0946
2025-04-19 17:53:43,598 | Epoch [1/3] Batch [9200] Loss: 4.9628
2025-04-19 17:53:46,041 | Epoch [1/3] Batch [9300] Loss: 5.1593
2025-04-19 17:53:48,485 | Epoch [1/3] Batch [9400] Loss: 5.0258
2025-04-19 17:53:50,932 | Epoch [1/3] Batch [9500] Loss: 5.0447
2025-04-19 17:53:53,378 | Epoch [1/3] Batch [9600] Loss: 4.9586
2025-04-19 17:53:55,825 | Epoch [1/3] Batch [9700] Loss: 4.9374
2025-04-19 17:53:58,271 | Epoch [1/3] Batch [9800] Loss: 5.1826
2025-04-19 17:54:00,715 | Epoch [1/3] Batch [9900] Loss: 4.9931
2025-04-19 17:54:03,165 | Epoch [1/3] Batch [10000] Loss: 4.9478
2025-04-19 17:54:05,619 | Epoch [1/3] Batch [10100] Loss: 5.0348
2025-04-19 17:54:08,066 | Epoch [1/3] Batch [10200] Loss: 4.9073
2025-04-19 17:54:10,510 | Epoch [1/3] Batch [10300] Loss: 4.9216
2025-04-19 17:55:02,572 | New best model with val loss: 6.2865
2025-04-19 17:55:02,573 | Epoch 1 | Train Loss: 5.8325 | Val Loss: 6.2865
2025-04-19 17:55:02,573 |   └─ Layer 1 Val Loss: 7.8719
2025-04-19 17:55:02,573 |   └─ Layer 2 Val Loss: 7.5714
2025-04-19 17:55:02,573 |   └─ Layer 3 Val Loss: 7.3243
2025-04-19 17:55:02,573 |   └─ Layer 4 Val Loss: 7.1557
2025-04-19 17:55:02,573 |   └─ Layer 5 Val Loss: 6.9205
2025-04-19 17:55:02,573 |   └─ Layer 6 Val Loss: 6.6550
2025-04-19 17:55:02,573 |   └─ Layer 7 Val Loss: 6.4292
2025-04-19 17:55:02,573 |   └─ Layer 8 Val Loss: 6.2865
2025-04-19 17:55:02,573 |   └─ Layer 9 Val Loss: 6.2865
2025-04-19 17:55:05,067 | Epoch [2/3] Batch [100] Loss: 4.9663
2025-04-19 17:55:07,515 | Epoch [2/3] Batch [200] Loss: 4.8499
2025-04-19 17:55:09,962 | Epoch [2/3] Batch [300] Loss: 4.9739
2025-04-19 17:55:12,409 | Epoch [2/3] Batch [400] Loss: 4.9499
2025-04-19 17:55:14,859 | Epoch [2/3] Batch [500] Loss: 4.9264
2025-04-19 17:55:17,330 | Epoch [2/3] Batch [600] Loss: 4.8729
2025-04-19 17:55:19,800 | Epoch [2/3] Batch [700] Loss: 4.8908
2025-04-19 17:55:22,272 | Epoch [2/3] Batch [800] Loss: 4.9421
2025-04-19 17:55:24,744 | Epoch [2/3] Batch [900] Loss: 4.8724
2025-04-19 17:55:27,213 | Epoch [2/3] Batch [1000] Loss: 4.8174
2025-04-19 17:55:29,685 | Epoch [2/3] Batch [1100] Loss: 4.8715
2025-04-19 17:55:32,174 | Epoch [2/3] Batch [1200] Loss: 4.8966
2025-04-19 17:55:34,691 | Epoch [2/3] Batch [1300] Loss: 4.8494
2025-04-19 17:55:37,181 | Epoch [2/3] Batch [1400] Loss: 4.8662
2025-04-19 17:55:39,676 | Epoch [2/3] Batch [1500] Loss: 4.6617
2025-04-19 17:55:42,165 | Epoch [2/3] Batch [1600] Loss: 4.8058
2025-04-19 17:55:44,635 | Epoch [2/3] Batch [1700] Loss: 4.7580
2025-04-19 17:55:47,104 | Epoch [2/3] Batch [1800] Loss: 4.8563
2025-04-19 17:55:49,575 | Epoch [2/3] Batch [1900] Loss: 4.6143
2025-04-19 17:55:52,044 | Epoch [2/3] Batch [2000] Loss: 4.7695
2025-04-19 17:55:54,513 | Epoch [2/3] Batch [2100] Loss: 4.7697
2025-04-19 17:55:56,979 | Epoch [2/3] Batch [2200] Loss: 4.7551
2025-04-19 17:55:59,424 | Epoch [2/3] Batch [2300] Loss: 4.6945
2025-04-19 17:56:01,870 | Epoch [2/3] Batch [2400] Loss: 4.8004
2025-04-19 17:56:04,328 | Epoch [2/3] Batch [2500] Loss: 4.8209
2025-04-19 17:56:06,773 | Epoch [2/3] Batch [2600] Loss: 4.6956
2025-04-19 17:56:09,220 | Epoch [2/3] Batch [2700] Loss: 4.8174
2025-04-19 17:56:11,665 | Epoch [2/3] Batch [2800] Loss: 4.6094
2025-04-19 17:56:14,112 | Epoch [2/3] Batch [2900] Loss: 4.7022
2025-04-19 17:56:16,560 | Epoch [2/3] Batch [3000] Loss: 4.5645
2025-04-19 17:56:19,007 | Epoch [2/3] Batch [3100] Loss: 4.6577
2025-04-19 17:56:21,452 | Epoch [2/3] Batch [3200] Loss: 4.6820
2025-04-19 17:56:23,898 | Epoch [2/3] Batch [3300] Loss: 4.6909
2025-04-19 17:56:26,344 | Epoch [2/3] Batch [3400] Loss: 4.5657
2025-04-19 17:56:28,794 | Epoch [2/3] Batch [3500] Loss: 4.6723
2025-04-19 17:56:31,241 | Epoch [2/3] Batch [3600] Loss: 4.6322
2025-04-19 17:56:33,687 | Epoch [2/3] Batch [3700] Loss: 4.5260
2025-04-19 17:56:36,143 | Epoch [2/3] Batch [3800] Loss: 4.6384
2025-04-19 17:56:38,589 | Epoch [2/3] Batch [3900] Loss: 4.4292
2025-04-19 17:56:41,038 | Epoch [2/3] Batch [4000] Loss: 4.5094
2025-04-19 17:56:43,487 | Epoch [2/3] Batch [4100] Loss: 4.5915
2025-04-19 17:56:45,936 | Epoch [2/3] Batch [4200] Loss: 4.5368
2025-04-19 17:56:48,382 | Epoch [2/3] Batch [4300] Loss: 4.5623
2025-04-19 17:56:50,830 | Epoch [2/3] Batch [4400] Loss: 4.6318
2025-04-19 17:56:53,276 | Epoch [2/3] Batch [4500] Loss: 4.5975
2025-04-19 17:56:55,721 | Epoch [2/3] Batch [4600] Loss: 4.4733
2025-04-19 17:56:58,167 | Epoch [2/3] Batch [4700] Loss: 4.6202
2025-04-19 17:57:00,612 | Epoch [2/3] Batch [4800] Loss: 4.6247
2025-04-19 17:57:03,065 | Epoch [2/3] Batch [4900] Loss: 4.5772
2025-04-19 17:57:05,521 | Epoch [2/3] Batch [5000] Loss: 4.6698
2025-04-19 17:57:07,965 | Epoch [2/3] Batch [5100] Loss: 4.5122
2025-04-19 17:57:10,412 | Epoch [2/3] Batch [5200] Loss: 4.4721
2025-04-19 17:57:12,859 | Epoch [2/3] Batch [5300] Loss: 4.3985
2025-04-19 17:57:15,308 | Epoch [2/3] Batch [5400] Loss: 4.4195
2025-04-19 17:57:17,755 | Epoch [2/3] Batch [5500] Loss: 4.4423
2025-04-19 17:57:20,202 | Epoch [2/3] Batch [5600] Loss: 4.5541
2025-04-19 17:57:22,647 | Epoch [2/3] Batch [5700] Loss: 4.3944
2025-04-19 17:57:25,092 | Epoch [2/3] Batch [5800] Loss: 4.3601
2025-04-19 17:57:27,539 | Epoch [2/3] Batch [5900] Loss: 4.4730
2025-04-19 17:57:29,985 | Epoch [2/3] Batch [6000] Loss: 4.3592
2025-04-19 17:57:32,434 | Epoch [2/3] Batch [6100] Loss: 4.4630
2025-04-19 17:57:34,892 | Epoch [2/3] Batch [6200] Loss: 4.3702
2025-04-19 17:57:37,338 | Epoch [2/3] Batch [6300] Loss: 4.4364
2025-04-19 17:57:39,784 | Epoch [2/3] Batch [6400] Loss: 4.4790
2025-04-19 17:57:42,229 | Epoch [2/3] Batch [6500] Loss: 4.3196
2025-04-19 17:57:44,675 | Epoch [2/3] Batch [6600] Loss: 4.2898
2025-04-19 17:57:47,122 | Epoch [2/3] Batch [6700] Loss: 4.3987
2025-04-19 17:57:49,568 | Epoch [2/3] Batch [6800] Loss: 4.2200
2025-04-19 17:57:52,015 | Epoch [2/3] Batch [6900] Loss: 4.3422
2025-04-19 17:57:54,460 | Epoch [2/3] Batch [7000] Loss: 4.4593
2025-04-19 17:57:56,906 | Epoch [2/3] Batch [7100] Loss: 4.3294
2025-04-19 17:57:59,353 | Epoch [2/3] Batch [7200] Loss: 4.3009
2025-04-19 17:58:01,823 | Epoch [2/3] Batch [7300] Loss: 4.3075
2025-04-19 17:58:04,311 | Epoch [2/3] Batch [7400] Loss: 4.3776
2025-04-19 17:58:06,783 | Epoch [2/3] Batch [7500] Loss: 4.3810
2025-04-19 17:58:09,251 | Epoch [2/3] Batch [7600] Loss: 4.3112
2025-04-19 17:58:11,722 | Epoch [2/3] Batch [7700] Loss: 4.4583
2025-04-19 17:58:14,213 | Epoch [2/3] Batch [7800] Loss: 4.3184
2025-04-19 17:58:16,707 | Epoch [2/3] Batch [7900] Loss: 4.3896
2025-04-19 17:58:19,203 | Epoch [2/3] Batch [8000] Loss: 4.3106
2025-04-19 17:58:21,702 | Epoch [2/3] Batch [8100] Loss: 4.3242
2025-04-19 17:58:24,196 | Epoch [2/3] Batch [8200] Loss: 4.2911
2025-04-19 17:58:26,692 | Epoch [2/3] Batch [8300] Loss: 4.3016
2025-04-19 17:58:29,164 | Epoch [2/3] Batch [8400] Loss: 4.1966
2025-04-19 17:58:31,638 | Epoch [2/3] Batch [8500] Loss: 4.2348
2025-04-19 17:58:34,115 | Epoch [2/3] Batch [8600] Loss: 4.2475
2025-04-19 17:58:36,586 | Epoch [2/3] Batch [8700] Loss: 4.2824
2025-04-19 17:58:39,055 | Epoch [2/3] Batch [8800] Loss: 4.2745
2025-04-19 17:58:41,501 | Epoch [2/3] Batch [8900] Loss: 4.2835
2025-04-19 17:58:43,949 | Epoch [2/3] Batch [9000] Loss: 4.1922
2025-04-19 17:58:46,395 | Epoch [2/3] Batch [9100] Loss: 4.2132
2025-04-19 17:58:48,842 | Epoch [2/3] Batch [9200] Loss: 4.3724
2025-04-19 17:58:51,289 | Epoch [2/3] Batch [9300] Loss: 4.3269
2025-04-19 17:58:53,736 | Epoch [2/3] Batch [9400] Loss: 4.1907
2025-04-19 17:58:56,182 | Epoch [2/3] Batch [9500] Loss: 4.1291
2025-04-19 17:58:58,627 | Epoch [2/3] Batch [9600] Loss: 4.0753
2025-04-19 17:59:01,074 | Epoch [2/3] Batch [9700] Loss: 4.0959
2025-04-19 17:59:03,521 | Epoch [2/3] Batch [9800] Loss: 4.0893
2025-04-19 17:59:05,971 | Epoch [2/3] Batch [9900] Loss: 4.3133
2025-04-19 17:59:08,420 | Epoch [2/3] Batch [10000] Loss: 4.0798
2025-04-19 17:59:10,865 | Epoch [2/3] Batch [10100] Loss: 4.1727
2025-04-19 17:59:13,311 | Epoch [2/3] Batch [10200] Loss: 4.1324
2025-04-19 17:59:15,760 | Epoch [2/3] Batch [10300] Loss: 4.1678
2025-04-19 18:00:07,830 | Epoch 2 | Train Loss: 4.5050 | Val Loss: 6.5230
2025-04-19 18:00:07,831 |   └─ Layer 1 Val Loss: 8.5358
2025-04-19 18:00:07,831 |   └─ Layer 2 Val Loss: 8.1189
2025-04-19 18:00:07,831 |   └─ Layer 3 Val Loss: 7.8559
2025-04-19 18:00:07,831 |   └─ Layer 4 Val Loss: 7.7028
2025-04-19 18:00:07,831 |   └─ Layer 5 Val Loss: 7.4455
2025-04-19 18:00:07,831 |   └─ Layer 6 Val Loss: 7.0833
2025-04-19 18:00:07,831 |   └─ Layer 7 Val Loss: 6.7416
2025-04-19 18:00:07,831 |   └─ Layer 8 Val Loss: 6.5230
2025-04-19 18:00:07,832 |   └─ Layer 9 Val Loss: 6.5230
2025-04-19 18:00:10,298 | Epoch [3/3] Batch [100] Loss: 4.1087
2025-04-19 18:00:12,742 | Epoch [3/3] Batch [200] Loss: 4.1413
2025-04-19 18:00:15,186 | Epoch [3/3] Batch [300] Loss: 4.0759
2025-04-19 18:00:17,631 | Epoch [3/3] Batch [400] Loss: 4.1177
2025-04-19 18:00:20,076 | Epoch [3/3] Batch [500] Loss: 4.2370
2025-04-19 18:00:22,521 | Epoch [3/3] Batch [600] Loss: 4.0909
2025-04-19 18:00:24,964 | Epoch [3/3] Batch [700] Loss: 4.1709
2025-04-19 18:00:27,408 | Epoch [3/3] Batch [800] Loss: 4.0455
2025-04-19 18:00:29,852 | Epoch [3/3] Batch [900] Loss: 4.0676
2025-04-19 18:00:32,297 | Epoch [3/3] Batch [1000] Loss: 4.0266
2025-04-19 18:00:34,745 | Epoch [3/3] Batch [1100] Loss: 4.0780
2025-04-19 18:00:37,189 | Epoch [3/3] Batch [1200] Loss: 4.0649
2025-04-19 18:00:39,634 | Epoch [3/3] Batch [1300] Loss: 4.0130
2025-04-19 18:00:42,076 | Epoch [3/3] Batch [1400] Loss: 4.0061
2025-04-19 18:00:44,520 | Epoch [3/3] Batch [1500] Loss: 4.1433
2025-04-19 18:00:46,958 | Epoch [3/3] Batch [1600] Loss: 3.9916
2025-04-19 18:00:49,395 | Epoch [3/3] Batch [1700] Loss: 4.0004
2025-04-19 18:00:51,839 | Epoch [3/3] Batch [1800] Loss: 4.0881
2025-04-19 18:00:54,302 | Epoch [3/3] Batch [1900] Loss: 3.9100
2025-04-19 18:00:56,766 | Epoch [3/3] Batch [2000] Loss: 4.0306
2025-04-19 18:00:59,226 | Epoch [3/3] Batch [2100] Loss: 3.9927
2025-04-19 18:01:01,689 | Epoch [3/3] Batch [2200] Loss: 4.0687
2025-04-19 18:01:04,160 | Epoch [3/3] Batch [2300] Loss: 4.1089
2025-04-19 18:01:06,624 | Epoch [3/3] Batch [2400] Loss: 4.0476
2025-04-19 18:01:09,087 | Epoch [3/3] Batch [2500] Loss: 4.0802
2025-04-19 18:01:11,550 | Epoch [3/3] Batch [2600] Loss: 3.9445
2025-04-19 18:01:14,013 | Epoch [3/3] Batch [2700] Loss: 3.9582
2025-04-19 18:01:16,477 | Epoch [3/3] Batch [2800] Loss: 3.9242
2025-04-19 18:01:18,930 | Epoch [3/3] Batch [2900] Loss: 4.0445
2025-04-19 18:01:21,368 | Epoch [3/3] Batch [3000] Loss: 3.9283
2025-04-19 18:01:23,807 | Epoch [3/3] Batch [3100] Loss: 4.0420
2025-04-19 18:01:26,246 | Epoch [3/3] Batch [3200] Loss: 3.9332
2025-04-19 18:01:28,685 | Epoch [3/3] Batch [3300] Loss: 3.8221
2025-04-19 18:01:31,123 | Epoch [3/3] Batch [3400] Loss: 3.9795
2025-04-19 18:01:33,562 | Epoch [3/3] Batch [3500] Loss: 4.0119
2025-04-19 18:01:36,012 | Epoch [3/3] Batch [3600] Loss: 3.9850
2025-04-19 18:01:38,451 | Epoch [3/3] Batch [3700] Loss: 4.0290
2025-04-19 18:01:40,888 | Epoch [3/3] Batch [3800] Loss: 3.9018
2025-04-19 18:01:43,326 | Epoch [3/3] Batch [3900] Loss: 3.9251
2025-04-19 18:01:45,763 | Epoch [3/3] Batch [4000] Loss: 3.9040
2025-04-19 18:01:48,201 | Epoch [3/3] Batch [4100] Loss: 3.8933
2025-04-19 18:01:50,640 | Epoch [3/3] Batch [4200] Loss: 3.9201
2025-04-19 18:01:53,077 | Epoch [3/3] Batch [4300] Loss: 4.0417
2025-04-19 18:01:55,516 | Epoch [3/3] Batch [4400] Loss: 4.1311
2025-04-19 18:01:57,955 | Epoch [3/3] Batch [4500] Loss: 4.0142
2025-04-19 18:02:00,393 | Epoch [3/3] Batch [4600] Loss: 3.9045
2025-04-19 18:02:02,831 | Epoch [3/3] Batch [4700] Loss: 3.9363
2025-04-19 18:02:05,278 | Epoch [3/3] Batch [4800] Loss: 3.8859
2025-04-19 18:02:07,717 | Epoch [3/3] Batch [4900] Loss: 3.8361
2025-04-19 18:02:10,156 | Epoch [3/3] Batch [5000] Loss: 3.9358
2025-04-19 18:02:12,594 | Epoch [3/3] Batch [5100] Loss: 3.9670
2025-04-19 18:02:15,034 | Epoch [3/3] Batch [5200] Loss: 4.0457
2025-04-19 18:02:17,474 | Epoch [3/3] Batch [5300] Loss: 3.8830
2025-04-19 18:02:19,913 | Epoch [3/3] Batch [5400] Loss: 4.0080
2025-04-19 18:02:22,353 | Epoch [3/3] Batch [5500] Loss: 3.8942
2025-04-19 18:02:24,791 | Epoch [3/3] Batch [5600] Loss: 3.7424
2025-04-19 18:02:27,230 | Epoch [3/3] Batch [5700] Loss: 3.8533
2025-04-19 18:02:29,669 | Epoch [3/3] Batch [5800] Loss: 3.8795
2025-04-19 18:02:32,109 | Epoch [3/3] Batch [5900] Loss: 3.8142
2025-04-19 18:02:34,568 | Epoch [3/3] Batch [6000] Loss: 3.8417
2025-04-19 18:02:37,007 | Epoch [3/3] Batch [6100] Loss: 3.8480
2025-04-19 18:02:39,446 | Epoch [3/3] Batch [6200] Loss: 3.7564
2025-04-19 18:02:41,884 | Epoch [3/3] Batch [6300] Loss: 3.7537
2025-04-19 18:02:44,323 | Epoch [3/3] Batch [6400] Loss: 3.8780
2025-04-19 18:02:46,761 | Epoch [3/3] Batch [6500] Loss: 3.9147
2025-04-19 18:02:49,200 | Epoch [3/3] Batch [6600] Loss: 3.7896
2025-04-19 18:02:51,638 | Epoch [3/3] Batch [6700] Loss: 3.8357
2025-04-19 18:02:54,078 | Epoch [3/3] Batch [6800] Loss: 3.7694
2025-04-19 18:02:56,516 | Epoch [3/3] Batch [6900] Loss: 3.8007
2025-04-19 18:02:58,956 | Epoch [3/3] Batch [7000] Loss: 3.8023
2025-04-19 18:03:01,396 | Epoch [3/3] Batch [7100] Loss: 3.7001
2025-04-19 18:03:03,835 | Epoch [3/3] Batch [7200] Loss: 3.7975
2025-04-19 18:03:06,280 | Epoch [3/3] Batch [7300] Loss: 3.6332
2025-04-19 18:03:08,720 | Epoch [3/3] Batch [7400] Loss: 3.7614
2025-04-19 18:03:11,159 | Epoch [3/3] Batch [7500] Loss: 3.8092
2025-04-19 18:03:13,599 | Epoch [3/3] Batch [7600] Loss: 3.8355
2025-04-19 18:03:16,038 | Epoch [3/3] Batch [7700] Loss: 3.7936
2025-04-19 18:03:18,477 | Epoch [3/3] Batch [7800] Loss: 3.7583
2025-04-19 18:03:20,916 | Epoch [3/3] Batch [7900] Loss: 3.7437
2025-04-19 18:03:23,355 | Epoch [3/3] Batch [8000] Loss: 3.6958
2025-04-19 18:03:25,793 | Epoch [3/3] Batch [8100] Loss: 3.6988
2025-04-19 18:03:28,232 | Epoch [3/3] Batch [8200] Loss: 3.7595
2025-04-19 18:03:30,675 | Epoch [3/3] Batch [8300] Loss: 3.7546
2025-04-19 18:03:33,145 | Epoch [3/3] Batch [8400] Loss: 3.7133
2025-04-19 18:03:35,615 | Epoch [3/3] Batch [8500] Loss: 3.7230
2025-04-19 18:03:38,079 | Epoch [3/3] Batch [8600] Loss: 3.6347
2025-04-19 18:03:40,544 | Epoch [3/3] Batch [8700] Loss: 3.6317
2025-04-19 18:03:43,009 | Epoch [3/3] Batch [8800] Loss: 3.6916
2025-04-19 18:03:45,473 | Epoch [3/3] Batch [8900] Loss: 3.7273
2025-04-19 18:03:47,937 | Epoch [3/3] Batch [9000] Loss: 3.7634
2025-04-19 18:03:50,404 | Epoch [3/3] Batch [9100] Loss: 3.6129
2025-04-19 18:03:52,870 | Epoch [3/3] Batch [9200] Loss: 3.6998
2025-04-19 18:03:55,334 | Epoch [3/3] Batch [9300] Loss: 3.7391
2025-04-19 18:03:57,786 | Epoch [3/3] Batch [9400] Loss: 3.7529
2025-04-19 18:04:00,226 | Epoch [3/3] Batch [9500] Loss: 3.6798
2025-04-19 18:04:02,667 | Epoch [3/3] Batch [9600] Loss: 3.5438
2025-04-19 18:04:05,124 | Epoch [3/3] Batch [9700] Loss: 3.6899
2025-04-19 18:04:07,565 | Epoch [3/3] Batch [9800] Loss: 3.6044
2025-04-19 18:04:10,004 | Epoch [3/3] Batch [9900] Loss: 3.7198
2025-04-19 18:04:12,443 | Epoch [3/3] Batch [10000] Loss: 3.6147
2025-04-19 18:04:14,882 | Epoch [3/3] Batch [10100] Loss: 3.6451
2025-04-19 18:04:17,321 | Epoch [3/3] Batch [10200] Loss: 3.7340
2025-04-19 18:04:19,760 | Epoch [3/3] Batch [10300] Loss: 3.5937
2025-04-19 18:05:11,773 | Epoch 3 | Train Loss: 3.8864 | Val Loss: 6.8696
2025-04-19 18:05:11,773 |   └─ Layer 1 Val Loss: 9.3228
2025-04-19 18:05:11,773 |   └─ Layer 2 Val Loss: 8.8103
2025-04-19 18:05:11,773 |   └─ Layer 3 Val Loss: 8.4610
2025-04-19 18:05:11,773 |   └─ Layer 4 Val Loss: 8.2176
2025-04-19 18:05:11,774 |   └─ Layer 5 Val Loss: 7.9006
2025-04-19 18:05:11,774 |   └─ Layer 6 Val Loss: 7.4860
2025-04-19 18:05:11,774 |   └─ Layer 7 Val Loss: 7.1012
2025-04-19 18:05:11,774 |   └─ Layer 8 Val Loss: 6.8696
2025-04-19 18:05:11,774 |   └─ Layer 9 Val Loss: 6.8696
2025-04-19 18:05:12,267 | Saved best model to decoder_checkpoints/best_decoder_d128_h8_l8_ff512_dp0.1_ls0_e1_val6.2865.pt
2025-04-19 18:05:12,267 | Training completed in 914.51s
2025-04-19 18:05:12,268 | Done!
